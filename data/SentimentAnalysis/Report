Naive Bayesian классификатор
Мы пытаемся понимать что-то про Почту России. Уже сразу понятно, что сильно хороших результатов добиться не удастся — слишком много всякого сарказма с ней связано.
Учимся — набор твитов на русском языке, собранных через streaming api по санкт-петербургу за примерно 1.5 месяца. Из них ищем твиты, содяржащие смайлы и делаем датасет для обучения
В итоге имеем такое кол-во «хороших» и «плохих» твитов — перекос в сторону хороших, а для почты россии будет наоборот.
wc -l happy_tweets
   12070 happy_tweets
wc -l sad_tweets
    2123 sad_tweets

Обучаемся. Провяряем на размеченных твитах с почтой россии:

    precision: 0.24561403508771928
    accuracy: 0.3891402714932127
    recall: 0.875
    F: 0.5387024608501119

Как и предполагалось — все достаточно печально. Причины — на самом деле у нас мало данных, твиттер очень специфичен, а в комбинации с русским языком вообще получаем, что один и тот же твит
можно трактовать несколькими различными способами. Вдобавок использовали только слова +  naive bayes  cам по себе достаточно плохой классификатор (особенно если данных мало)

