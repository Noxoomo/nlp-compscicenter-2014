 Данные, на которых учились — в папке data/classifiersData/naiveBayes
 Учился на своих статьях, проверял на чьих-то других (в задание написано, что протестировать на своих, но это как-то странно — naive bayes на таком малом кол-ве документов
 выдает 100% угадывание (и не удивительно, у нас мало слов и документы по ним отличаются)

Результаты нашего классификатора (кроме просто разбиения на слова, еще все переведен в lowercase, удаленны служебные символы, а также порезаны некоторые окончания):

good vs bad
precision: 0.5
accuracy: 0.8
recall: 0.5
F: 0.6153846153846154

bad vs good:
precision: 0.875
accuracy: 0.8
recall: 0.875
F: 0.8358208955223881

Weka: из результатов можно предположить, что weka отсутсвующие слова обрабатывает не так, как самописный классификатор (вдобавок в weka нету обработки знаков препинания, преобразования в lowercase…)


bad vs good:

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 1         1          0.8       1         0.889      0.5      bad
                 0         0          0         0         0          0.778    good
Weighted Avg.    0.8       0.8        0.64      0.8       0.711      0.556

=== Confusion Matrix ===

  a  b   <-- classified as
 24  0 |  a = bad
  6  0 |  b = good

  good vs bad

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0         0          0         0         0          0.778    good
                 1         1          0.8       1         0.889      0.5      bad
Weighted Avg.    0.8       0.8        0.64      0.8       0.711      0.556

=== Confusion Matrix ===

  a  b   <-- classified as
  0  6 |  a = good
  0 24 |  b = bad


