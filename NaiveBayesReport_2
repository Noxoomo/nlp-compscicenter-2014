 Новые отчет: теперь вероятности суммируются в единицу и в weka использовался чисто те же данные, что и в нашем.


Наш результат

precision: 0.6
accuracy: 0.8333333333333334
recall: 0.5
F: 0.625

Если поменять классы местами:
precision: 0.88
accuracy: 0.8333333333333334
recall: 0.9166666666666666
F: 0.8730158730158729

good bad
3   3   good
2   22  bad

Выводы — скорее всего мой классификатор и классификатор от weka придает разный вес словам, которые до этого не встречались.

(А вывод про то, что на таком небольшом кол-ве текстов учиться не стоит уже был и относится к предыдущему дз)


 === Detailed Accuracy By Class ===

                TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                  0.958     0.833      0.821     0.958     0.885      0.736    bad
                  0.167     0.042      0.5       0.167     0.25       0.764    good
 Weighted Avg.    0.8       0.675      0.757     0.8       0.758      0.742

 === Confusion Matrix ===

   a  b   <-- classified as
  23  1 |  a = bad
   5  1 |  b = good
